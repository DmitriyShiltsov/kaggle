{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import zipfile\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "итого 141032\r\n",
      "drwxrwxr-x 2 sda sda     4096 июн 28 00:52 .\r\n",
      "drwxrwxr-x 4 sda sda     4096 июн 27 23:04 ..\r\n",
      "-rw-rw-r-- 1 sda sda 16054568 июн 27 22:43 digit-recognizer.zip\r\n",
      "-rw-rw-r-- 1 sda sda   212908 июн 28 02:04 result.csv\r\n",
      "-rw-rw-r-- 1 sda sda   240909 июн 28 02:11 sample_submission.csv\r\n",
      "-rw-rw-r-- 1 sda sda 51118296 июн 28 02:11 test.csv\r\n",
      "-rw-rw-r-- 1 sda sda 76775041 июн 28 02:11 train.csv\r\n"
     ]
    }
   ],
   "source": [
    "zip_f = zipfile.ZipFile('data/digits/digit-recognizer.zip','r')\n",
    "zip_f.extractall('data/digits/')\n",
    "zip_f.close()\n",
    "\n",
    "!ls -la 'data/digits/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!cat 'data/digits/train.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((42000, 785),\n",
       " Index(['label', 'pixel0', 'pixel1', 'pixel2', 'pixel3', 'pixel4', 'pixel5',\n",
       "        'pixel6', 'pixel7', 'pixel8',\n",
       "        ...\n",
       "        'pixel774', 'pixel775', 'pixel776', 'pixel777', 'pixel778', 'pixel779',\n",
       "        'pixel780', 'pixel781', 'pixel782', 'pixel783'],\n",
       "       dtype='object', length=785))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/digits/train.csv')\n",
    "df.shape, df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.iloc[:41000,0]\n",
    "X = scale(df.iloc[:41000,1:].values.reshape(41000,28,28))\n",
    "\n",
    "y_val = df.iloc[41000:,0]\n",
    "X_val = scale(df.iloc[41000:,1:].values.reshape(1000,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 (28, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd4e4c05550>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# попробую поизвлекать картинки\n",
    "i = 11\n",
    "\n",
    "print(y[i], X[i].shape)\n",
    "plt.imshow(X[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape(41000,28,28,1)\n",
    "X_val = X_val.reshape(1000,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 26, 26, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 24, 24, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 20, 20, 32)        25632     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 8, 8, 64)          18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 6, 6, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 6, 6, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 2, 2, 64)          102464    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 512)               33280     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 494,922\n",
      "Trainable params: 494,538\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# хочу сделать прикольную модельку с рюшечками с финтиклюшечками так чтобы вау\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), input_shape=(28,28,1)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv2D(32, (3,3), input_shape=(28,28,1)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv2D(32, (5,5)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), input_shape=(28,28,1)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), input_shape=(28,28,1)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv2D(64, (5,5)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),   \n",
    "    tf.keras.layers.Dense(512, activation='relu'),    \n",
    "    tf.keras.layers.Dense(10, activation = 'softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "             loss = 'sparse_categorical_crossentropy',\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "  24/1282 [..............................] - ETA: 7:51 - loss: 1.4876 - accuracy: 0.4844"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-6691fab54f96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X, y, epochs=5, validation_data=(X_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.history.history\n",
    "#loss[['loss', 'val_loss']].plot()\n",
    "#loss[['accuracy', 'val_accuracy']].plot()\n",
    "#loss.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28000, 784)\n",
      "(28000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "X_test = pd.read_csv('data/digits/test.csv')\n",
    "print(X_test.shape)\n",
    "X_test = X_test.values.reshape(28000,28,28,1)\n",
    "print(X_test.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageId  Label\n",
       "0        1      2\n",
       "1        2      0\n",
       "2        3      9\n",
       "3        4      9\n",
       "4        5      3"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'ImageId': np.arange(1, X_test.shape[0]+1),\n",
    "                   'Label': np.argmax(prediction, axis=-1)})\n",
    "df.head()                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/digits/result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
